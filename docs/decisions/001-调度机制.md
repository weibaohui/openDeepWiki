# Go任务调度器（Orchestrator）代码优化操作指引
## 前置说明
本指引基于最新版`orchestrator`代码，需解决**重试无限循环、性能低效、数据丢失、灵活性差、可观测性不足**等生产环境级问题，优化后需保证代码可运行、逻辑闭环、满足高可用调度要求。

## 核心优化步骤
### 步骤1：限制任务重试次数，解决无限循环问题
#### 优化目标
给任务增加重试次数上限，避免仓库锁竞争/池提交失败的任务无限循环占用资源。
#### 操作详情
1. 扩展`Job`结构体，新增重试次数、最大重试次数、自定义超时字段；
2. 改造`NewTaskJob`函数，初始化新增字段；
3. 改造`tryDispatch`函数，增加重试次数校验，超过上限则放弃并重打日志；
4. 改造`executeJob`函数，支持任务执行失败后的指数退避重试。
#### 代码修改示例
```go
// 1. 扩展Job结构体
type Job struct {
	TaskID       uint
	RepositoryID uint
	EnqueuedAt   time.Time
	RetryCount   int           // 当前重试次数
	MaxRetries   int           // 最大重试次数
	Timeout      time.Duration // 自定义任务超时
}

// 2. 改造NewTaskJob函数
func NewTaskJob(taskID, repositoryID uint) *Job {
	return &Job{
		TaskID:       taskID,
		RepositoryID: repositoryID,
		EnqueuedAt:   time.Now(),
		RetryCount:   0,
		MaxRetries:   5, // 默认最大重试5次
		Timeout:      10 * time.Minute, // 默认超时10分钟
	}
}

// 3. 改造tryDispatch函数（仅修改重试入队逻辑）
func (o *Orchestrator) tryDispatch(job *Job) {
	if !o.acquireRepoLock(job.RepositoryID) {
		// 检查重试次数上限
		if job.RetryCount >= job.MaxRetries {
			klog.Warningf("Job reach max retries: taskID=%d, repoID=%d, retries=%d",
				job.TaskID, job.RepositoryID, job.RetryCount)
			return
		}
		// 重试次数+1后入队
		job.RetryCount++
		if err := o.retryQueue.Enqueue(job); err != nil {
			klog.Errorf("Failed to enqueue retry job: taskID=%d, repoID=%d, err=%v",
				job.TaskID, job.RepositoryID, err)
		}
		return
	}

	lockReleased := false
	defer func() {
		if !lockReleased {
			o.releaseRepoLock(job.RepositoryID)
		}
	}()

	err := o.pool.Submit(func() {
		lockReleased = true
		defer o.releaseRepoLock(job.RepositoryID)
		o.executeJob(job)
	})
	if err != nil {
		klog.Errorf("Failed to submit job to pool: taskID=%d, repoID=%d, err=%v", job.TaskID, job.RepositoryID, err)
		// 池提交失败也检查重试次数
		if job.RetryCount < job.MaxRetries {
			job.RetryCount++
			if err := o.retryQueue.Enqueue(job); err != nil {
				klog.Errorf("Failed to re-enqueue job: taskID=%d, repoID=%d, err=%v",
					job.TaskID, job.RepositoryID, err)
			}
		}
	}
}

// 4. 改造executeJob函数，增加执行失败重试（需先导入math包：import "math"）
func (o *Orchestrator) executeJob(job *Job) {
	defer func() {
		if r := recover(); r != nil {
			klog.Errorf("Task panic recovered: taskID=%d, repoID=%d, err=%v", job.TaskID, job.RepositoryID, r)
			o.unregisterCancel(job.TaskID, job.RepositoryID)
		}
	}()

	ctx, cancel := context.WithTimeout(o.ctx, job.Timeout)
	defer cancel()
	runCtx, manualCancel := context.WithCancel(ctx)
	defer manualCancel()

	o.registerCancel(job.TaskID, job.RepositoryID, manualCancel)
	defer o.unregisterCancel(job.TaskID, job.RepositoryID)

	var err error
	// 剩余重试次数 = 最大重试次数 - 当前已重试次数
	remainingRetries := job.MaxRetries - job.RetryCount
	for i := 0; i <= remainingRetries; i++ {
		err = o.executor.ExecuteTask(runCtx, job.TaskID)
		if err == nil {
			klog.V(6).Infof("Task completed: taskID=%d, repoID=%d", job.TaskID, job.RepositoryID)
			return
		}
		// 指数退避等待
		backoff := time.Duration(math.Pow(2, float64(i))) * time.Second
		klog.Warningf("Task retry %d/%d failed: taskID=%d, err=%v (backoff %v)",
			i+1, remainingRetries, job.TaskID, err, backoff)
		
		select {
		case <-runCtx.Done():
			err = runCtx.Err()
			break
		case <-time.After(backoff):
		}
	}

	// 最终失败打日志
	klog.Errorf("Task failed after all retries: taskID=%d, repoID=%d, err=%v",
		job.TaskID, job.RepositoryID, err)
}
```

### 步骤2：优化dispatchLoop性能，移除多余sleep
#### 优化目标
删除`dispatchLoop`中无意义的sleep，降低任务分发延迟，提升调度实时性。
#### 操作详情
修改`dispatchLoop`函数，移除`Dequeue`返回`false`时的`time.Sleep(50 * time.Millisecond)`，直接返回退出循环。
#### 代码修改示例
```go
func (o *Orchestrator) dispatchLoop() {
	for {
		select {
		case <-o.ctx.Done():
			return
		default:
			// Dequeue本身会阻塞等待新任务，无需额外sleep
			job, ok := o.jobQueue.Dequeue()
			if !ok {
				return // 队列已关闭，直接退出
			}
			o.tryDispatch(job)
		}
	}
}
```

### 步骤3：修复重试队列入队错误忽略问题
#### 优化目标
移除所有`_ = o.retryQueue.Enqueue(job)`的错误忽略写法，增加日志告警，避免任务丢失无感知。
#### 操作详情
遍历代码中所有`retryQueue.Enqueue`调用处，替换错误忽略写法，增加错误日志。
#### 代码修改示例
```go
// 已在步骤1的tryDispatch函数中完成该修改，核心点：
// 1. 替换 _ = o.retryQueue.Enqueue(job) 为带err校验的写法
// 2. 错误时打Error级别日志，明确任务ID和仓库ID
```

### 步骤4：支持自定义任务超时
#### 优化目标
将`executeJob`中硬编码的10分钟超时改为使用`Job`结构体的`Timeout`字段，支持按任务自定义超时。
#### 操作详情
修改`executeJob`函数中`context.WithTimeout`的超时参数，从固定`10*time.Minute`改为`job.Timeout`；新增`SetTimeout`方法方便外部设置超时。
#### 代码修改示例
```go
// 1. 给Job新增SetTimeout方法
func (j *Job) SetTimeout(timeout time.Duration) {
	j.Timeout = timeout
}

// 2. executeJob中已在步骤1完成超时参数修改，核心代码：
// ctx, cancel := context.WithTimeout(o.ctx, job.Timeout)
```

### 步骤5：增加重试队列协程Panic防护
#### 优化目标
给`processRetryQueue`函数增加Panic防护，避免单个任务panic导致整个重试队列协程退出。
#### 操作详情
1. 在`processRetryQueue`函数顶部增加defer recover逻辑，panic时重启协程；
2. 对循环内的`tryDispatch`调用增加独立的Panic防护，避免单个任务panic中断循环。
#### 代码修改示例
```go
func (o *Orchestrator) processRetryQueue() {
	defer o.retryTicker.Stop()
	// 增加协程级Panic防护，避免协程退出
	defer func() {
		if r := recover(); r != nil {
			klog.Errorf("Retry queue loop panic recovered: %v", r)
			// 重启协程
			go o.processRetryQueue()
		}
	}()

	for {
		select {
		case <-o.ctx.Done():
			return
		case <-o.retryTicker.C:
			for i := 0; i < 10; i++ {
				job, ok := o.retryQueue.Dequeue()
				if !ok {
					break
				}
				// 单个任务Panic不影响整个循环
				func() {
					defer func() {
						if r := recover(); r != nil {
							klog.Errorf("Retry dispatch panic: taskID=%d, repoID=%d, err=%v",
								job.TaskID, job.RepositoryID, r)
						}
					}()
					o.tryDispatch(job)
				}()
			}
		}
	}
}
```

### 步骤6：增加Prometheus监控指标（可选，如需集成监控）
#### 优化目标
增加核心监控指标，覆盖队列长度、任务执行、锁竞争等维度，便于观测系统状态。
#### 操作详情
1. 导入Prometheus相关包；
2. 定义监控指标变量；
3. 在关键逻辑（入队、锁竞争、任务执行）中更新指标；
4. 改造`GetQueueStatus`函数，同步更新队列长度指标。
#### 代码修改示例
```go
// 1. 先导入依赖包
import (
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
	"time"
)

// 2. 定义监控指标
var (
	// 队列指标
	queueLength = promauto.NewGaugeVec(prometheus.GaugeOpts{
		Name: "orchestrator_queue_length",
		Help: "Length of job queue",
	}, []string{"queue_type"}) // main/retry

	// 任务指标
	taskExecutions = promauto.NewCounterVec(prometheus.CounterOpts{
		Name: "orchestrator_task_executions_total",
		Help: "Total number of task executions",
	}, []string{"status", "repo_id"}) // success/failure/timeout

	taskExecutionDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{
		Name:    "orchestrator_task_duration_seconds",
		Help:    "Duration of task execution",
		Buckets: prometheus.DefBuckets,
	}, []string{"status", "repo_id"})

	// 重试指标
	taskRetries = promauto.NewCounterVec(prometheus.CounterOpts{
		Name: "orchestrator_task_retries_total",
		Help: "Total number of task retries",
	}, []string{"repo_id"})

	// 锁竞争指标
	repoLockContention = promauto.NewCounterVec(prometheus.CounterOpts{
		Name: "orchestrator_repo_lock_contention_total",
		Help: "Total number of repo lock contentions",
	}, []string{"repo_id"})
)

// 3. 改造EnqueueJob函数，更新队列长度指标
func (o *Orchestrator) EnqueueJob(job *Job) error {
	select {
	case <-o.ctx.Done():
		return ErrOrchestratorStopped
	default:
	}

	if err := o.jobQueue.Enqueue(job); err != nil {
		if errors.Is(err, ErrQueueFull) {
			klog.Warningf("Job queue full: taskID=%d, repoID=%d", job.TaskID, job.RepositoryID)
		}
		return err
	}
	// 更新队列长度指标
	queueLength.WithLabelValues("main").Inc()
	klog.V(6).Infof("Job enqueued: taskID=%d, repoID=%d", job.TaskID, job.RepositoryID)
	return nil
}

// 4. 改造tryDispatch函数，更新锁竞争指标
func (o *Orchestrator) tryDispatch(job *Job) {
	if !o.acquireRepoLock(job.RepositoryID) {
		// 更新锁竞争指标
		repoLockContention.WithLabelValues(fmt.Sprintf("%d", job.RepositoryID)).Inc()
		// 后续重试逻辑...
		return
	}
	// 剩余逻辑...
}

// 5. 改造executeJob函数，更新任务执行指标
func (o *Orchestrator) executeJob(job *Job) {
	start := time.Now()
	// 原有panic防护、上下文、重试逻辑...

	// 任务执行完成后更新指标
	duration := time.Since(start).Seconds()
	repoID := fmt.Sprintf("%d", job.RepositoryID)
	if err == nil {
		taskExecutions.WithLabelValues("success", repoID).Inc()
		taskExecutionDuration.WithLabelValues("success", repoID).Observe(duration)
	} else {
		taskExecutions.WithLabelValues("failure", repoID).Inc()
		taskExecutionDuration.WithLabelValues("failure", repoID).Observe(duration)
	}
}

// 6. 改造GetQueueStatus函数，同步更新队列指标
func (o *Orchestrator) GetQueueStatus() *QueueStatus {
	o.repoMutex.Lock()
	defer o.repoMutex.Unlock()

	// 更新监控指标
	queueLength.WithLabelValues("main").Set(float64(o.jobQueue.Len()))
	queueLength.WithLabelValues("retry").Set(float64(o.retryQueue.Len()))

	return &QueueStatus{
		QueueLength:   o.jobQueue.Len(),
		ActiveWorkers: o.pool.Running(),
		ActiveRepos:   len(o.repoConcurrency),
	}
}
```

### 步骤7：增加任务幂等性保障（业务层建议）
#### 优化目标
避免任务重试导致重复执行，保障业务数据一致性。
#### 操作详情
1. 扩展`Job`结构体增加幂等性键字段；
2. 示例化执行器层的幂等性校验逻辑（需结合业务实现）。
#### 代码修改示例
```go
// 1. 扩展Job结构体
type Job struct {
	TaskID          uint
	RepositoryID    uint
	EnqueuedAt      time.Time
	RetryCount      int
	MaxRetries      int
	Timeout         time.Duration
	IdempotencyKey  string // 幂等性键，格式建议："repo-{repoID}-task-{taskID}"
}

// 2. 改造NewTaskJob，初始化幂等性键
func NewTaskJob(taskID, repositoryID uint) *Job {
	return &Job{
		TaskID:         taskID,
		RepositoryID:   repositoryID,
		EnqueuedAt:     time.Now(),
		RetryCount:     0,
		MaxRetries:     5,
		Timeout:        10 * time.Minute,
		IdempotencyKey: fmt.Sprintf("repo-%d-task-%d", repositoryID, taskID),
	}
}

// 3. 执行器层幂等性校验示例（需业务侧实现）
type MyExecutor struct {
	completedTasks sync.Map // 已完成任务缓存，生产环境建议用Redis持久化
}

func (e *MyExecutor) ExecuteTask(ctx context.Context, taskID uint) error {
	// 需先通过taskID获取对应的Job对象，拿到IdempotencyKey
	// 此处为示例，需结合业务逻辑调整
	job := getJobByTaskID(taskID)
	if job == nil {
		return errors.New("task not found")
	}

	// 幂等性校验
	if _, ok := e.completedTasks.Load(job.IdempotencyKey); ok {
		klog.V(6).Infof("Task already completed (idempotent): taskID=%d", taskID)
		return nil
	}

	// 执行核心任务逻辑
	err := e.doExecuteTask(ctx, taskID)
	if err == nil {
		// 标记任务已完成
		e.completedTasks.Store(job.IdempotencyKey, true)
	}
	return err
}

// 辅助函数（需业务侧实现）
func getJobByTaskID(taskID uint) *Job {
	// 从存储/缓存中获取Job对象
	return nil
}

func (e *MyExecutor) doExecuteTask(ctx context.Context, taskID uint) error {
	// 核心业务逻辑
	return nil
}
```

## 验收标准
1. 代码可正常编译运行，无语法错误；
2. 任务重试次数达到`MaxRetries`后停止重试，并打印Warning日志；
3. `dispatchLoop`函数无多余sleep，任务入队后可立即被分发；
4. 所有`retryQueue.Enqueue`调用均有错误校验和日志，无`_ =` 忽略错误的写法；
5. 支持通过`job.SetTimeout`自定义任务超时，覆盖默认10分钟；
6. `processRetryQueue`函数中单个任务panic不会导致协程退出，也不会中断循环；
7. （若集成监控）Prometheus指标可正常采集，包含队列长度、任务执行状态、锁竞争次数；
8. （若实现幂等性）重复执行同一任务时，仅第一次执行核心逻辑，后续直接返回成功。